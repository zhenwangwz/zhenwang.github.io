<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zhen Wang</title>
  
  <meta name="author" content="Zhen Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zhen Wang</name>
              </p>
              <p> I am a Ph.D. student in the <a href="http://www.ee.ucla.edu/" target="_blank">Electrical and Computer Engineering Department</a> at <a href="http://www.ucla.edu/" target="_blank">University of California, Los Angeles</a>. I am a member of the <a href="https://visual.ee.ucla.edu/" target="_blank">Visual Machines Group</a>, where I am fortunate to be advised by <a href="https://www.ee.ucla.edu/achuta-kadambi/" target="_blank">Prof. Achuta Kadambi</a>.
              </p>
              <p>
               I obtained my Master's degree from <a href="http://www.columbia.edu/" target="_blank">Columbia University</a>, where I worked with <a href="http://www.columbia.edu/~jwp2128/" target="_blank">Prof. John Paisley</a> and <a href="http://www.stat.columbia.edu/~liam/" target="_blank">Prof. Liam Paninski</a>. 
	      </p>
      	      <p>
	      Before that, I obtained my Bachelor's Degree at <a href="https://en.uestc.edu.cn/" target="_blank">University of Electronic Science and Technology of China (UESTC)</a>. During my undergraduate, I also spent some time at <a href="https://www.cornell.edu/" target="_blank">Cornell University</a> and <a href="https://www.lmu.de/en/" target="_blank">LMU MÃ¼nchen</a>. 
	      </p>

<!--               <p style="text-align:center"> -->
               Feel free to contact me at <a href="mailto:zhenwang@ucla.edu" target="_blank">zhenwang@ucla.edu</a>.
<!--               </p> -->
	         <p style="text-align:center">
<!--                 <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
<!--                 <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=KLV2bXwAAAAJ&hl=en&authuser=2">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/zhenwangwz">Twitter</a>  &nbsp/&nbsp
			 <a href="https://www.linkedin.com/in/zhen-w-4164bb139">LinkedIn</a> &nbsp/&nbsp
			 <a href="https://www.facebook.com/zhenwangwz">Facebook</a>
<!--                 <a href="https://github.com/jonbarron/">Github</a> -->
              </p>
            </td>
            <td style="padding:1.1%;width:55%;max-width:80%">
<!-- 	      <img src="imgs/IMG_6965.jpg" class='img-fluid'> -->
<!-- 	    <div class="col-sm-3 offset-sm-1"> -->
              <a href="imgs/IMG_6965.jpg"><img width="160" height="180" src="imgs/IMG_6965.jpg" class="img-fluid"></a>
<!--             </div> -->
            </td>	  
         </tr>
	 </tbody></table>
		
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
	  <tr>
	  <td style="padding:20px;width:100%;vertical-align:middle">
	    <heading>News</heading>
	    <ul>
	      <li>Jun 2022:</font> One paper on rPPG augmentation conditionally accepted in ICCP '22.
	      </li>
            </ul>  
		  
	    <ul>
	      <li>Jun 2022:</font> Our lab is going to CVPR '22 in person. Come and say hello! 
	      </li>    
		    
	    </ul>  
	    <ul>
	      <li>Mar 2022:</font> One paper accepted in CVPR '22. Stay tuned!
	      </li>

	    </ul>  
	  </td>
	</tr>
	</tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	         <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Experience</heading>
              <p>
		<strong>Meta</strong>, Burlingame, CA 
	       </br>Research Scientist Intern, Jun. 2024 - Present
		</br>
		</br>
	        <strong>Google</strong>, Playa Vista, CA 
	       </br>Student Researcher, Sept. 2023 - Jun. 2024
		</br> 
		</br>
		  <strong>Google</strong>, Mountain View, CA 
	       </br>Student Researcher, Jun. 2023 - Sept. 2023
		</br> 
		</br>
		 <strong>Columbia | The Mortimer B. Zuckerman Mind Brain Behavior Institute </strong>, New York, NY
	       </br>Research Staff Assistant, Sept. 2019 - Jun. 2020
		</br> 
		</br>
              </p>
	    

	
            </td>
          </tr>
	</tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected papers</heading>
              <p> 
               In general, I'm interested in computer vision and its application in machine autonomy and digital health. I'm passionate about problems in capture (sensing and reconstruction) & synthesis (rendering) of the physical world to all the subtleties, ranging from indoor and natural outdoor scenes to human face and body. 
             </p> 
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	<tr>    
             <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="imgs/d2dgm_teaser.png" alt="clean-usnob" width="230" height="113">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="zhenwangwz.github.io">
              <papertitle>Dynamic 2D Gaussian Mesh: Temporally Consistent Surface Reconstruction
from Monocular Videos</papertitle>
              </a>
              <br>
	      <strong>Zhen Wang</strong>,
		<a href="https://ychfan.github.io/">Yuchen Fan</a>, 
		<a href="https://scholar.google.com/citations?user=wy5I3fwAAAAJ&hl=zh-CN">Wei Ye</a>, 
		<a href="https://scholar.google.com/citations?hl=en&user=uZMP-_oAAAAJ&view_op=list_works&sortby=pubdate">Zhongxi Li</a>, 
		<a href="https://www.linkedin.com/in/jq-huang/">JQ Huang</a>, 
		<a href="https://www.linkedin.com/in/rakesh-r-3848538/">Rakesh Ranjan</a>,
              <a href="https://www.ee.ucla.edu/achuta-kadambi/">Achuta Kadambi</a>, 
	        <br>
<!--               <br>
              <em>arXiv</em>, 2024 (coming soon)
              <br> -->
		    <font color="#FF0000">In submission,
		    <a href="https://zhenwangwz.github.io/">Project website</a>
              <p></p>
			     <p></font>Temporally consistent reconstruction from monocular videos enables various downstream tasks such as physcis-based simulation and editing.</p>
            </td>
          <tr>
		  
	  <tr>    
             <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="imgs/mvdd.gif" alt="clean-usnob" width="230" height="113">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2312.04875">
              <papertitle>MVDD: Multi-View Depth Diffusion Models</papertitle>
              </a>
              <br>
	      <strong>Zhen Wang</strong>,
		<a href="https://xharlie.github.io/">Qiangeng Xu</a>, 
		<a href="https://scholar.google.com/citations?user=qsrpuKIAAAAJ&hl=en">Feitong Tan</a>, 
		<a href="https://mlchai.com/">Menglei Chai</a>, 
		<a href="https://shichenliu.github.io/">Shichen Liu</a>, 
		<a href="https://www.linkedin.com/in/rohit-pandey-bab10b7a/">Rohit Pandey</a>,
	        <a href="https://www.seanfanello.it/">Sean Fanello</a>,
              <a href="https://www.ee.ucla.edu/achuta-kadambi/">Achuta Kadambi</a>, 
	      <a href="https://www.zhangyinda.com/">Yinda Zhang</a>,
	        <br>
<!--               <br>
              <em>CVPR</em>, 2022
              <br> -->
		    <font color="#FF0000">ECCV 2024,
		    <a href="https://mvdepth.github.io/">Project website</a>
              <p></p>
			     <p></font>Multi-view depths as a novel 3D representation for 3d shape generation, completion and regularization.</p>
            </td>
          <tr>
		  
  	<tr>    
             <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="imgs/teaser_png.png" alt="clean-usnob" width="230" height="113">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://arxiv.org/abs/2212.04096">
              <papertitle>ALTO: Alternating Latent Topologies for Implicit 3D Reconstruction</papertitle>
              </a>
              <br>
	      <strong>Zhen Wang*</strong>,
              Shijie Zhou*,
		<a href="https://jjparkcv.github.io/">Jeong Joon Park</a>, 
		<a href="https://paschalidoud.github.io/">Despoina Paschalidou</a>, Suya You, 
		<a href="https://stanford.edu/~gordonwz/">Gordon Wetzstein</a>, 
		<a href="https://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a>,
              <a href="https://www.ee.ucla.edu/achuta-kadambi/">Achuta Kadambi</a>, 
	        <br>
<!--               <br>
              <em>CVPR</em>, 2022
              <br> -->
		    <font color="#FF0000">CVPR 2023,
		    <a href="https://visual.ee.ucla.edu/alto.htm/">Project website</a>
              <p></p>
			     <p></font>Rethinking latent topologies for fast and detailed implicit 3D reconstructions. </p>
            </td>
          <tr>
		  
          <tr>    
             <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="imgs/avatars_video_demo_zw.gif" alt="clean-usnob" width="230" height="113">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Synthetic_Generation_of_Face_Videos_With_Plethysmograph_Physiology_CVPR_2022_paper.pdf">
              <papertitle>Synthetic Generation of Face Videos with Plethysmograph Physiology</papertitle>
              </a>
              <br>
	      <strong>Zhen Wang*</strong>,
              <a href="https://yhba-ucla.github.io">Yunhao Ba*</a>,
              Pradyumna Chari,
	      Oyku Deniz Bozkurt, 
	      Gianna Brown, Parth Patwa, Niranjan Vaddi, Laleh Jalilian,
              <a href="https://www.ee.ucla.edu/achuta-kadambi/">Achuta Kadambi</a>, 
	        <br>
<!--               <br>
              <em>CVPR</em>, 2022
              <br> -->
		    <font color="#FF0000">CVPR 2022, 
		    <a href="https://visual.ee.ucla.edu/rppg_avatars.htm/">Project website</a>
              <p></p>
			    <p></font>A scalable biophysical neural rendering method to generate biorealistic synthetic rPPG videos given any reference image and target blood flow. </p>
            </td>
          <tr>
	
		  
          <tr>    
             <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="imgs/pipeline.png" alt="clean-usnob" width="230" height="113">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2106.06007">
              <papertitle>Style Transfer with Bio-realistic Appearance Manipulation for Skin-tone Inclusive rPPG</papertitle>
              </a>
              <br>
              <a href="https://yhba-ucla.github.io">Yunhao Ba*</a>,
	      <strong>Zhen Wang*</strong>,
              Kerim Doruk Karinca, 
	      Oyku Deniz Bozkurt, 
              <a href="https://www.ee.ucla.edu/achuta-kadambi/">Achuta Kadambi</a>, 
	        <br>
<!--               <br>
              <em>arXiv</em>, 2021 
              <br> -->
	            <font color="#FF0000">ICCP 2022,
		    <a href="https://visual.ee.ucla.edu/rppg_augmentation.htm/">Project website</a>
              <p></p>
		      <p></font>A first attempt that transfers light-skinned subjects to dark skin tones while preserving the pulse signals in the facial videos. </p>
            </td>
          <tr>
    

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Talks</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td width="100%" valign="center">
	      	     
	      July 2023 (Mountain View, CA): Recent advances in 3d shape generation, Google AR reading group <br />

	      August 2022 (Pasadena, CA): IEEE International Conference on Computational Photography (ICCP) 2022 | <a href="https://youtu.be/vCWv37kS8-Q?t=4363">Video</a> <br />
		  
              April 2022 (Caltech): Synthetic Generation of Face Videos with Plethysmograph Physiology (Host: Prof. <a href="http://users.cms.caltech.edu/~klbouman/">Katie Bouman</a>)
              <br><br>
            
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td width="100%" valign="center">
              CVPR 2025, ICML 2025, ECCV 2024, CVPR 2024, ICLR 2024, AAAI 2024, NeurIPS 2023, ICCV 2023, Neural Fields @ ICLR 2023, CVPR 2023, APSIPA Transactions on Signal and Information Processing 2023 (Editor: Prof. C.-C. Jay Kuo), SDM 2021, AAAI 2021.
              <br><br>
            
            </td>
          </tr>
        </tbody></table>
	      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Thanks to <a href="https://jonbarron.info/">Jon Barron</a> for the source code of this website. 
<!--                If you like, you can add a star to Job Barron's <a href="https://jonbarron.info/">personal page</a>.-->
<!--                <br>-->
<!--                <a href="https://clustrmaps.com/site/1bhsk"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=SmVNKAru4SRtedjTqTTFYIJmNGoHTrBK5VOIsscudyM&cl=ffffff" /></a>-->
              </p>
            </td>
          </tr>
        </tbody></table>
  
</body>

</html>
